HIDDEN_LAYER_PARAMS = (128, 128, 128, 64)

TRAINING_STEPS = 2_000_000
INITIAL_COLLECTION_STEPS = 1_000
COLLECT_STEPS_PER_ITERATION = 1
REPLAY_BUFFER_MAX_LENGTH = 500_000

PARALLEL_CALLS = 32
BATCH_SIZE = 1024
LEARNING_RATE = 3e-4
LOG_STEPS_INTERVAL = 20_000
NUMBER_OF_EVAL_EPISODES = 10
EVAL_STEPS_INTERVAL = 20_000
POLICY_SAVER_INTERVAL = 500_000

STARTING_EPSILON = 0.8
EPSILON_DECAY_COUNT = 2_000_000
ENDING_EPSILON = 0.1
DISCOUNT_FACTOR = 0.999
TD_ERROR_LOSS_FUNCTION = common.element_wise_squared_loss
TRAIN_STEP_COUNTER = 0

DATE = '09.15.22'
NOTES =''
CHECKPOINT_DIRECTORY = 'TrainedAgents'
TIME_LIMIT = 250

INIT_POLICY = None # --> Random Policy

--------- NOTES -----------
Difficulty Level 0.
Reward Function: +1 when hit pole, -1 when hit plant.
hit pole no matter what the azimuth is.

